{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfermarkt Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.transfermarkt.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseContinent(ref):\n",
    "    \n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + \"/\" + ref\n",
    "\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    response = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    leagues = []\n",
    "    rows = response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"odd\"})\n",
    "    rows += response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"even\"})\n",
    "\n",
    "    for row in rows:\n",
    "        val = row.find(\"td\",{\"class\":\"rechts hauptlink\"}).text\n",
    "        val = \".\".join(val.split(\",\"))\n",
    "        rest = val.split(\" \")[1]\n",
    "        val = val.split(\" \")[0]\n",
    "        if \"Bill\" in rest:\n",
    "            val = float(val) * 10**9\n",
    "        else:\n",
    "            if \"Mill\" in rest:\n",
    "                val = float(val) * 10**6\n",
    "            else: \n",
    "                val = 0\n",
    "        if val > 200*10**6:\n",
    "            league = {}\n",
    "            league[\"href\"] = row.findAll('a')[1]['href']\n",
    "            league[\"name\"] = row.find(\"img\")[\"title\"]\n",
    "            league[\"country\"] = row.find(\"td\",{\"class\",\"zentriert\"}).find(\"img\")[\"title\"]\n",
    "            league[\"tot_value\"] = val\n",
    "            leagues.append(league)\n",
    "            \n",
    "    return leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlayers(club_page):\n",
    "    players = []\n",
    "    players_infos = club_page.find(\"div\", {\"id\":\"yw1\"}).find(\"table\", {\"class\":\"items\"}).find(\"tbody\").find_all(\"tr\", recursive=False)\n",
    "    for player_info in players_infos:\n",
    "        player = {}\n",
    "        player_info = player_info.find(\"a\", {\"class\":\"spielprofil_tooltip\"})\n",
    "        player[\"name\"] = player_info[\"title\"]\n",
    "        player[\"id\"] = player_info[\"id\"]\n",
    "        player[\"href\"] = player_info[\"href\"]\n",
    "        players.append(player)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_league(league_ref): #get clubs in league\n",
    "\n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + league_ref\n",
    "    clubs = []\n",
    "    \n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    response = BeautifulSoup(r.text, 'html.parser')\n",
    "    rows = response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"odd\"})\n",
    "    rows += response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"even\"})\n",
    "    \n",
    "    for row in rows:\n",
    "            \n",
    "            url_club = base_url + row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['href']\n",
    "            r_club = requests.get(url_club, headers=HEADERS)\n",
    "            response_club = BeautifulSoup(r_club.text, 'html.parser')\n",
    "            stadium_info =response_club.find(\"div\",{\"id\":\"main\"}).findAll(\"span\",{\"class\":\"dataValue\"})[4].text\n",
    "            \n",
    "            stadium_info=stadium_info.replace(u'\\xa0',u'')\n",
    "            stadium_info=stadium_info.replace(u'\\n',u'')\n",
    "\n",
    "\n",
    "            split_stadium= re.split(r'(\\d+)',stadium_info)\n",
    "            stadium = split_stadium[0]\n",
    "#             num_seats = float(split_stadium[1]+'.'+split_stadium[3])\n",
    "           \n",
    "            \n",
    "            club = {}\n",
    "            club[\"name\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['title']\n",
    "            club[\"href\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['href']\n",
    "            club[\"squad\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].text\n",
    "            club[\"market_value\"] = row.find(\"td\",{\"class\":\"rechts show-for-small show-for-pad nowrap\"}).text\n",
    "            club[\"stadium\"] = stadium\n",
    "            \n",
    "            players = getPlayers(BeautifulSoup(r_club.text, 'html.parser'))\n",
    "            club[\"players\"] = players\n",
    "#             club[\"stadium_seats\"] = num_seats\n",
    "            clubs.append(club)  \n",
    "    \n",
    "    return clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePlayer(player_page, player_ref):    \n",
    "    \n",
    "    response = BeautifulSoup(player_page, 'html.parser')\n",
    "    \n",
    "    playerInfos = str(response.find(\"table\", {\"class\":\"auflistung\"}))\n",
    "    player = {}\n",
    "    player[\"href\"] = player_ref\n",
    "    try:\n",
    "        player[\"number\"] = response.find(\"span\", {\"class\":\"dataRN\"}).text\n",
    "    except:\n",
    "        player[\"number\"] = None\n",
    "    player[\"name\"] = response.find(\"h1\", {\"itemprop\":\"name\"}).text\n",
    "    player[\"player_id\"] = player_ref.split(\"/\")[-1]\n",
    "    position = BeautifulSoup(playerInfos.split(\"Position\")[1], 'html.parser').find(\"td\").text\n",
    "    reg = re.compile( \"[a-zA-Z -]\")\n",
    "    player[\"position\"] = \"\".join(reg.findall(position))\n",
    "    player[\"birthdate\"] = BeautifulSoup(playerInfos.split(\"Date of birth\")[1], 'html.parser').find(\"td\").text\n",
    "    player[\"nationality\"] = BeautifulSoup(playerInfos.split(\"Nationality\")[1], 'html.parser').find(\"td\").find(\"img\")[\"title\"]\n",
    "    player[\"current_club\"] = BeautifulSoup(playerInfos.split(\"Current club\")[1], 'html.parser').find(\"td\").find_all(\"a\")[-1].text\n",
    "\n",
    "    try:\n",
    "        transfers = []\n",
    "        trans = response.find(\"div\",{\"class\" : \"box transferhistorie\"}).find(\"table\").find(\"tbody\").find_all(\"tr\", {\"class\":\"zeile-transfer\"})\n",
    "\n",
    "        for t in trans:\n",
    "            transfer = {}\n",
    "            transfer[\"player\"] = player_ref.split(\"/\")[-1]\n",
    "            transfer[\"date\"] = t.find_all(\"td\", {\"class\":\"zentriert hide-for-small\"})[1].text\n",
    "            transfer[\"from\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[0].find(\"a\")[\"id\"]\n",
    "            transfer[\"to\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[1].find(\"a\")[\"id\"]\n",
    "            if (t.find(\"td\", {\"class\":\"zelle-abloese\"}).text) == \"End of loan\" or t.find(\"td\", {\"class\":\"zelle-abloese\"}).text ==\"Loan\":\n",
    "                transfer[\"fee\"] = t.find(\"td\", {\"class\":\"zelle-mw\"}).text\n",
    "            else: \n",
    "                transfer[\"fee\"] = t.find(\"td\",{\"class\":\"zelle-abloese\"}).text\n",
    "\n",
    "            transfers.append(transfer)\n",
    "    except:\n",
    "        transfers = None\n",
    "        \n",
    "    return player, transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlayersPage(player_ref):\n",
    "        \n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + player_ref\n",
    "\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nleagues = parseContinent(\"wettbewerbe/europa\")\\nleagues += parseContinent(\"wettbewerbe/amerika\")\\nleagues += parseContinent(\"wettbewerbe/asien\")\\nwith open(\"data/leagues.json\", \"w\") as out:\\n    json.dump(leagues, out)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "leagues = parseContinent(\"wettbewerbe/europa\")\n",
    "leagues += parseContinent(\"wettbewerbe/amerika\")\n",
    "leagues += parseContinent(\"wettbewerbe/asien\")\n",
    "with open(\"data/leagues.json\", \"w\") as out:\n",
    "    json.dump(leagues, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leagues: 23\n",
      "Premier League\n",
      "Serie A\n",
      "Ligue 1\n",
      "Liga NOS\n",
      "Eredivisie\n",
      "Super League\n",
      "Raiffeisen Super League\n",
      "LaLiga\n",
      "1.Bundesliga\n",
      "SÃ¼per Lig\n",
      "Premier Liga\n",
      "Jupiler Pro League\n",
      "Premier Liga\n",
      "HET Liga\n",
      "Campeonato Brasileiro SÃ©rie A\n",
      "Liga MX Clausura\n",
      "Major League Soccer\n",
      "Campeonato Brasileiro SÃ©rie B\n",
      "Primera DivisiÃ³n\n",
      "Liga MX Apertura\n",
      "Liga Ãguila I\n",
      "Chinese Super League\n",
      "J1 League\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/leagues.json\", \"r\") as in_file:\n",
    "    leagues = json.load(in_file)\n",
    "    \n",
    "print(\"Number of leagues: \" + str(len(leagues)))\n",
    "for league in leagues:\n",
    "    print(league[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'England',\n",
       " 'href': '/premier-league/startseite/wettbewerb/GB1',\n",
       " 'name': 'Premier League',\n",
       " 'tot_value': 5790000000.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leagues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclubs = []\\nfor league in leagues:\\n    clubs += parse_league(league[\"href\"])\\n    \\nwith open(\"data/clubs.json\", \"w\") as out:\\n    json.dump(clubs, out)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clubs = []\n",
    "for league in leagues:\n",
    "    clubs += parse_league(league[\"href\"])\n",
    "    \n",
    "with open(\"data/clubs.json\", \"w\") as out:\n",
    "    json.dump(clubs, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/clubs.json\", \"r\") as in_file:\n",
    "    clubs = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplayer_list = []\\n\\nfor club in clubs:\\n    players = club[\"players\"]\\n    for player in players:\\n        player_list.append(player[\"href\"])\\n\\nwith open(\"data/players_ref.json\", \"w\") as out:\\n    json.dump(player_list, out)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "player_list = []\n",
    "\n",
    "for club in clubs:\n",
    "    players = club[\"players\"]\n",
    "    for player in players:\n",
    "        player_list.append(player[\"href\"])\n",
    "\n",
    "with open(\"data/players_ref.json\", \"w\") as out:\n",
    "    json.dump(player_list, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/players_ref.json\", \"r\") as in_file:\n",
    "    players_list = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor player_ref in players_list:\\n    player_id = player_ref.split(\"/\")[-1]\\n     \\n    directory = \\'data/players/\\' + player_id + \"/\"\\n    fname = directory + \"page.html\"\\n\\n    if os.path.isfile(fname) == False:\\n        if os.path.exists(directory) == False:\\n            os.makedirs(directory)\\n        page = getPlayersPage(player_ref)\\n        with open(fname, \"w\")as out:\\n            json.dump(page, out)  \\n        time.sleep(0.5)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for player_ref in players_list:\n",
    "    player_id = player_ref.split(\"/\")[-1]\n",
    "     \n",
    "    directory = 'data/players/' + player_id + \"/\"\n",
    "    fname = directory + \"page.html\"\n",
    "\n",
    "    if os.path.isfile(fname) == False:\n",
    "        if os.path.exists(directory) == False:\n",
    "            os.makedirs(directory)\n",
    "        page = getPlayersPage(player_ref)\n",
    "        with open(fname, \"w\")as out:\n",
    "            json.dump(page, out)  \n",
    "        time.sleep(0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 1000/12075 players.\n",
      "Scraped 2000/12075 players.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3244df1e78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mplayer_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsePlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d9ab91dac464>\u001b[0m in \u001b[0;36mparsePlayer\u001b[0;34m(player_page, player_ref)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplayerInfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"auflistung\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\abiyounes\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         criteria.\"\"\"\n\u001b[1;32m   1277\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\abiyounes\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[1;31m# BS3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[1;31m# BS2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\abiyounes\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\abiyounes\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m         \u001b[1;31m# If it's text, make sure the text matches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\abiyounes\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36msearch_tag\u001b[0;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[1;32m   1639\u001b[0m             \u001b[0mmarkup_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         call_function_with_tag_data = (\n\u001b[0;32m-> 1641\u001b[0;31m             \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m             and not isinstance(markup_name, Tag))\n\u001b[1;32m   1643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for player_ref in players_list:\n",
    "    player_id = player_ref.split(\"/\")[-1]\n",
    "     \n",
    "    directory = 'data/players/' + player_id + \"/\"\n",
    "    fname = directory + \"info.json\"\n",
    "\n",
    "    with open(directory + \"page.html\", \"r\") as in_file:\n",
    "        player_page = json.load(in_file)\n",
    "\n",
    "    player = parsePlayer(player_page, player_ref)\n",
    "    with open(fname, \"w\") as out:\n",
    "        json.dump(player, out)  \n",
    "\n",
    "    i+= 1\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Scraped \" + str(i) + \"/\" + str(len(players_list)) + \" players.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': 'Jan 16, 2012',\n",
       "  'fee': 'Â£7.56m',\n",
       "  'from': '355',\n",
       "  'player': '66587',\n",
       "  'to': '631'},\n",
       " {'date': 'Jan 30, 2008',\n",
       "  'fee': 'Â£5.40m',\n",
       "  'from': '405',\n",
       "  'player': '66587',\n",
       "  'to': '355'},\n",
       " {'date': 'Dec 31, 2007',\n",
       "  'fee': 'Â£1.80m',\n",
       "  'from': '350',\n",
       "  'player': '66587',\n",
       "  'to': '405'},\n",
       " {'date': 'Sep 19, 2007',\n",
       "  'fee': 'Â£1.80m',\n",
       "  'from': '405',\n",
       "  'player': '66587',\n",
       "  'to': '350'},\n",
       " {'date': 'May 9, 2005',\n",
       "  'fee': 'Â£45k',\n",
       "  'from': '1132',\n",
       "  'player': '66587',\n",
       "  'to': '405'},\n",
       " {'date': 'Nov 9, 2004',\n",
       "  'fee': '-',\n",
       "  'from': '405',\n",
       "  'player': '66587',\n",
       "  'to': '1132'},\n",
       " {'date': 'Jul 1, 2004',\n",
       "  'fee': '-',\n",
       "  'from': '6933',\n",
       "  'player': '66587',\n",
       "  'to': '405'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# player_url = \"https://www.transfermarkt.co.uk/gary-cahill/profil/spieler/27511\"\n",
    "# HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "# r = requests.get(player_url, headers=HEADERS)\n",
    "\n",
    "# response = BeautifulSoup(r.text, 'html.parser')\n",
    "# trans = response.find(\"div\",{\"class\" : \"box transferhistorie\"}).find(\"table\").find(\"tbody\").find_all(\"tr\", {\"class\":\"zeile-transfer\"})\n",
    "# transfers = []\n",
    "# for t in trans:\n",
    "#             transfer = {}\n",
    "#             transfer[\"player\"] = player_ref.split(\"/\")[-1]\n",
    "#             transfer[\"date\"] = t.find_all(\"td\", {\"class\":\"zentriert hide-for-small\"})[1].text\n",
    "#             transfer[\"from\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[0].find(\"a\")[\"id\"]\n",
    "#             transfer[\"to\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[1].find(\"a\")[\"id\"]\n",
    "#             if (t.find(\"td\", {\"class\":\"zelle-abloese\"}).text) == \"End of loan\" or t.find(\"td\", {\"class\":\"zelle-abloese\"}).text ==\"Loan\":\n",
    "#                 transfer[\"fee\"] = t.find(\"td\", {\"class\":\"zelle-mw\"}).text\n",
    "#             else: \n",
    "#                 transfer[\"fee\"] = t.find(\"td\",{\"class\":\"zelle-abloese\"}).text\n",
    "\n",
    "#             transfers.append(transfer)\n",
    "# transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
